{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Wrangling\n",
    "\n",
    "<br>\n",
    "\n",
    "Thomas Donoghue\n",
    "\n",
    "COGS 108 - January 23rd, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## High Level Learning Goals\n",
    "\n",
    "- Notice that data is everywhere, ripe for collection and analysis\n",
    "- However, dealing with data is mostly 'administrative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## How are we going to do this:\n",
    "\n",
    "- A crash course on file types, data formats, databases, and APIs\n",
    "- Explore how to load and organize data into useable formats\n",
    "- Develop some heuristics for dealing with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Sources\n",
    "\n",
    "- Files\n",
    "- Databases\n",
    "- Web Scraping & APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data 'Friendliness'\n",
    "\n",
    "The degree to which a data filetype easily lends itself to useful analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/xkcd_tasks.png\" alt=\"sql\" height=\"350\" width=\"250\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 'Friendly' File Types:\n",
    "\n",
    "- csv\n",
    "- tsv\n",
    "- json\n",
    "- txt\n",
    "- xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 'Unfriendly' File Types:\n",
    "- pdf\n",
    "- docx\n",
    "- html\n",
    "- Anything made to look nice for humans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CSV Files\n",
    "\n",
    "- 'Comma Separated Value' files store data, separated by comma's. \n",
    "- Think of them like lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4\r\n",
      "5, 6, 7, 8\r\n",
      "9, 10, 11, 12"
     ]
    }
   ],
   "source": [
    "# Note: through this notebook, I will be using '!' to run the shell command 'cat'\n",
    "#  to print out the content of example data files\n",
    "\n",
    "!cat files/dat.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Python has a module devoted to working with csv's\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,  2,  3,  4\n",
      "5,  6,  7,  8\n",
      "9,  10,  11,  12\n"
     ]
    }
   ],
   "source": [
    "# We can read through our file with the csv module\n",
    "with open('files/dat.csv') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        print(', '.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Pandas also has functions to directly load csv data\n",
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3\n",
       "0  1   2   3   4\n",
       "1  5   6   7   8\n",
       "2  9  10  11  12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in our csv file\n",
    "pd.read_csv('files/dat.csv', header=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### JSON\n",
    "\n",
    "- JavaScript Object Notation files can store hierachical key/value pairings. \n",
    "- Think of them like dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"firstName\": \"John\",\r\n",
      "  \"age\": 53\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!cat files/dat.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'firstName': 'John', 'age': '53'}\n"
     ]
    }
   ],
   "source": [
    "# Think of json's as similar to dictionaries\n",
    "d = {'firstName': 'John', 'age': '53'}\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Python also has a module for dealing with json\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Load a json file\n",
    "with open('files/dat.json') as dat_file:    \n",
    "    dat = json.load(dat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Check what data type this gets loaded as\n",
    "print(type(dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Pandas also has support for reading in json files\n",
    "pd.read_json?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first          Alan\n",
       "place    Manchester\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can read in json formatted strings with pandas\n",
    "pd.read_json('{ \"first\": \"Alan\", \"place\": \"Manchester\"}', typ='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            53\n",
       "firstName    John\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in our json file with pandas\n",
    "pd.read_json('files/dat.json', typ='series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### XML\n",
    "\n",
    "- eXtensible Markup Language files store 'tagged' data. \n",
    "- Think of them like HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<person>\r\n",
      "\t<who>Claude</who>\r\n",
      "\t<what>Info</who>\r\n",
      "\t<when>50s</when>\r\n",
      "</person>"
     ]
    }
   ],
   "source": [
    "!cat files/dat.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We can read in the XML file with standard python I/O\n",
    "with open('files/dat.xml') as dat_file:\n",
    "    dat = dat_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<person>\\n\\t<who>Claude</who>\\n\\t<what>Info</who>\\n\\t<when>50s</when>\\n</person>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the data\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Beautiful Soup has functions to 'clean up' XML into human-friendlier formats\n",
    "from bs4 import BeautifulSoup\n",
    "nice_dat = BeautifulSoup(dat, 'xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<person>\n",
      "<who>Claude</who>\n",
      "<what>Info</what>\n",
      "<when>50s</when>\n",
      "</person>\n"
     ]
    }
   ],
   "source": [
    "# Check out the parsed data\n",
    "print(nice_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Text Files\n",
    "\n",
    "- Text files store (unstructured) text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an unstructured text file.\r\n",
      "    It can have all sorts\r\n",
      "        of\r\n",
      "            stuff in it.\r\n",
      "\r\n",
      "\r\n",
      "Super duper."
     ]
    }
   ],
   "source": [
    "!cat files/dat.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PDFs\n",
    "\n",
    "- 'Portable Document Files' are a format to render complex data documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%PDF-1.3\r\n",
      "%���������\r\n",
      "4 0 obj\r\n",
      "<< /Length 5 0 R /Filter /FlateDecode >>\r\n",
      "stream\r\n",
      "x\u0001]�=\u000b",
      "�0\u0010����ǭ\u001d",
      "L�h\u00122���\u0015\u000e\u001c",
      "ĩحB��\u0007��\"�\r",
      "wܽ�so�#�syc\t��~r�E{�\f",
      "���k��5�l�QYG���N9��*�jE�l-dS\u0004�h���p�l���]��?��\u0006\u001fâ���X���\"%�\f",
      "ܩ�\r",
      "[�,��!'\b�2\u000f1o6\r",
      "\u000f���>/�1�\r\n",
      "endstream\r\n",
      "endobj\r\n",
      "5 0 obj\r\n",
      "153\r\n",
      "endobj\r\n",
      "2 0 obj\r\n",
      "<< /Type /Page /Parent 3 0 R /Resources 6 0 R /Contents 4 0 R /MediaBox [0 0 612 792]\r\n",
      ">>\r\n",
      "endobj\r\n",
      "6 0 obj\r\n",
      "<< /ProcSet [ /PDF /Text ] /ColorSpace << /Cs1 7 0 R >> /Font << /TT1 8 0 R\r\n",
      ">> >>\r\n",
      "endobj\r\n",
      "9 0 obj\r\n",
      "<< /Length 10 0 R /N 3 /Alternate /DeviceRGB /Filter /FlateDecode >>\r\n",
      "stream\r\n",
      "x\u0001��wTS�\u0016�Ͻ7��\u0012\" %�\u001az\t �;H\u0015\u0004Q�I�P\u0002��&vD\u0005F\u0014\u0011)VdT�\u0001G�\"cE\u0014\u000b",
      "��b�\t�\u0010P��QDE�݌k\t�5�ޚ��Y�����g�}׺\u0000P��\u0004�tX\u0001�4�X\u0014���\\\u0012\u0013���\u0002\u0018\u0010\u0001\u000eX\u0001��ff\u0004G�D\u0002���=���HƳ��.�d��,�P&s���\"7C$\u0006\u0000\r\n",
      "E�6<~&\u0017�\u0002�S��\u00192�\u0004���)2�12\u0016�\t��\"�įl���+�ɘ�&�\u001aY�\u0019�4���Pޚ%ᣌ\u0004�\\�%�g�|\u0007e�TI�\u0000��(����L\u00000\u0014�_��&�l�2E\u0014\u0019��\u0002\u0000\b��9�r\u000e��9h�\u0000x�g�\u0004�Ib�\u0011טi���f��S�b1+��M�xL���\f",
      "�0\u0017��o�E\u0001%Ym�h���\u001c",
      "��Y��h����\u001e",
      "~S�=�z�U�&�ϞA��Y�l�/�\u0016\u0000�$Z�\u001d",
      "���U\u0000�m\u0006@��O� \u0000�\u0005\u0000�ޜ�\u001e",
      "�l^���\f",
      "'\u000b",
      "���ls\u0001�k.+�7���oʿ�9�����V;�\u0017?�#I\u00153eE妧�KD��\f",
      "\u000e��d��\u0010���9i���,���\u0017��UQ�\t��h��<�X�.d\r\n",
      "���\u00186'\u0007\u0019~�k\u0014hu_\u0000}�9P�I\u0007�o=\u0000C#\u0003$n?z\u0002}�[\u00101\r\n",
      "Ⱦ�h���s�2z���\u001f\u000b",
      "\\�n�LA\"S��\f",
      "�dr%�,\u0019�߄l�\u0002\u0012�\u0007t�\r\n",
      "4�.0\u0002,`\r",
      "\u001c",
      "�3p\u0003� \u0000��H\u0010\u0003�\u0003.H\u0002i@\u0004�A>�\u0000\r\n",
      "A1�\u0001v�jp\u0000ԁz�\u0004N�6p\u0006\\\u0004W�\r",
      "p\u000b",
      "\f",
      "�G@\r\n",
      "��K0\u0001ށi\b��\u0010\u0015�A��\u0016�\u000f�B�\u0010\u001bZ\byCAP8\u0014\u0003�C��\u0010�@��&�\u0018*���CP=�#t\u001a�\b]���\u0007� 4\u0006�\u0001}�\u0011�\u0002�a\r",
      "�\u0000��ٰ;\u001c",
      "\bG���Dx\u0015�\u0007\u0017���J�\u0016>\u000e��\u0017�\u001b�\u0000,�_\b@�\b\u0003�FX\b\u001b�DB�X$\u0001\u0011!k�\"�\u0002�E��\u000e�\u001b��H�q�\u0003\u0006��a�\u0018\u0016�\u0019�Y��bVa�bJ0՘c�VL\u0017�6f\u00103����bձ�X'�?v\t6\u0011��-�V`�`[���\u0003�a�;\u001c",
      "\u000e��\u0019�\u001c",
      "p~�\u0018\\2n5�\u0004�\u000f׌����\r",
      "�&�x�*�\u0014�\u000f�s�b|!�\r\n",
      "\u001c",
      "\u001e",
      "ߏ\u001fƿ'�\tZ\u0004k�\u000f!� $l$T\u0010\u001a\b�\b��\u0011�4Q��Ot\"�\u0010y�\\b)���A�I\u001c",
      "&N�\u0014I�$\u0017R$)���TIj\"]&=&�!��:dGr\u0018Y@^O�$� _%\u000f�?P�(&\u0014OJ\u001c",
      "EB�N9J�@y@yC�R\r",
      "�n�X����ZO�D}J}/G�3���ɭ���k��{%O�חw�_.�'_!J����\u0002Q�@�S���V�F��=�IE���b�b�b�b��5�Q%�����\u0012O�@��%�!\u001aBӥyҸ�M�:�e�0\u001d",
      "G7��ӓ���\u001f��\te%e[�(�\u001c",
      "�\u001a��R\u0006�0`�3R\u0019��������4�����6�i^��)��*n*|�\"�f�\u0001���LUo�\u0014՝�m�O�0j&jaj�j��.��ϧ�w�ϝ_4����갺�z��j���=�\u001a�\u001a�\u001a\u0019\u001aU\u001a�4�5\u0019�n�ɚ��4ǴhZ\u000b",
      "�\u0004Z�Z�^0����Tf%��9�����-�>�ݫ=�c��Xg�N��\u0013]�.[7A�\\�SwBOK/X/_�Q�>Q�����G�[��� �`�A�������a�a��c#����*�Z�;�8c�q��>�[&���I�I��MS���T`�ϴ�\f",
      "k�h&4�5�Ǣ��YY�F֠9�<�|�y��+\u000b",
      "=�X��\u0016�\u0016_,�,S-�,\u001fY)Y\u0005Xm�����Ěk]c}ǆj�c�Φ�浭�-�v��};�]��\u0016�N���\u000e�\"�&�1\u0007=�x��\u000e��tv(��}�\u0011������\u0007'{'��I�ߝY�)�\r",
      "Σ\u000b",
      "\f",
      "\u0017�\u0017�-\u0018r�q�\u001c",
      "r�.d.�_xp��Uە�Z���M׍�v�m���=����+\u000fK\u000f�G�ǔ���\u001a�\u000b",
      "^���W�W����b�j�>:>�>�>\u0013�v��}/�a�\u0002�v���������O\u00048\u0004�\t�\r\n",
      "�\u0004F\u0004V\u0007>\u000b",
      "2\t\u0012\u0005u\u0004��\u0001���\u001f/�_$\\�\u0016\u0002B�Cv�<\t5\f",
      "]\u0015�s\u0018.,4�&�y�Ux~xw\u0004-bEDCĻH����G��\u0016K\u0016wF�G�E�GME{E�EK�X,Y��F�Z� �=\u0016\u001f\u001b\u0015{$vr����K����\r\n",
      "��.3\\����r���Ϯ�_�Yq*\u001e",
      "\u001b\u001f\u001d",
      "�\u0010��\u0013©�L��_�w�\u0004ד������+��]�e��\u0004�����D��]�cI�I\u0015I�\u0002OA��u�_�䩔���)3�ѩ�i�����B%a��+]3='�/�4�0C��i��U\u0013�@ёL(sYf����L�H�$�%�Y\u000b",
      "�j��gGe��Q�\u0011����n�\u001d",
      "����~5f5wug�v����5�k\u000e��֮\\۹Nw]������m mH���Fˍe\u001b�n���Q�Q��`h����B�BQ�-�[\u000el�l\u0015l��f��jۗ\"^��b���O%ܒ��Y}W�����������w�v\bw����X�bY^�Ю�]�����W�Va[q`\u000fi�d��2���J�jGէ��\u001a����{�����׿�m�\u0001�\u0003�\u0007>\u001e",
      "\u0014\u001c",
      "���Pk�Am�a�����꺿g_D�H��G�G��u�;��7�7�6�Ʊ�q�o���C{\u0013��P3���\u00048!9����\u001f�\f",
      "<�y�}��'�����Z�Z���։��6i{L{��ӝ\u001d",
      "�\u001d",
      "-?��|������gKϑ�\u0015��9�w~�Bƅ�\u0017�:Wt>���ҝ����ˁ��^�r�۽��U��g�9];}�}�����\u001e",
      "���_�~i��m��p���㭎�\u0005}��]�/���}���\u001b\u0003�\u0006��.�{�^�=�}���\u0007�\u000f^?�z8�h�c��'\r\n",
      "O*��?�����f�����`ϳ�g���C/����O�\u0005ϩ�+F�F�G�Gό���z����ˌ��ㅿ)����ѫ�~w��gb���k��?Jި�9���m�d���wi獵�ޫ�?�����c�Ǒ��O�O���?w|\t��x&mf������\r\n",
      "endstream\r\n",
      "endobj\r\n",
      "10 0 obj\r\n",
      "2612\r\n",
      "endobj\r\n",
      "7 0 obj\r\n",
      "[ /ICCBased 9 0 R ]\r\n",
      "endobj\r\n",
      "3 0 obj\r\n",
      "<< /Type /Pages /MediaBox [0 0 612 792] /Count 1 /Kids [ 2 0 R ] >>\r\n",
      "endobj\r\n",
      "11 0 obj\r\n",
      "<< /Type /Catalog /Pages 3 0 R >>\r\n",
      "endobj\r\n",
      "8 0 obj\r\n",
      "<< /Type /Font /Subtype /TrueType /BaseFont /CIDSZH+Helvetica /FontDescriptor\r\n",
      "12 0 R /Encoding /MacRomanEncoding /FirstChar 33 /LastChar 84 /Widths [ 278\r\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 667 0 0 722\r\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 611 ] >>\r\n",
      "endobj\r\n",
      "12 0 obj\r\n",
      "<< /Type /FontDescriptor /FontName /CIDSZH+Helvetica /Flags 32 /FontBBox [-951 -481 1445 1122]\r\n",
      "/ItalicAngle 0 /Ascent 770 /Descent -230 /CapHeight 717 /StemV 98 /XHeight\r\n",
      "523 /StemH 85 /AvgWidth 441 /MaxWidth 1500 /FontFile2 13 0 R >>\r\n",
      "endobj\r\n",
      "13 0 obj\r\n",
      "<< /Length 14 0 R /Length1 5904 /Filter /FlateDecode >>\r\n",
      "stream\r\n",
      "x\u0001�X\u000b",
      "p\u0014Ǚ����}I�w�@+���ްz�\u0004H<��b\r",
      "Ү�\u0010�\u0005��.F����W\r\n",
      "\r\n",
      "*,+�\t��\u0001c\u0016��!\u0010Ǥp�;;\u0006�h\u0010�o\u0004\u0005'S�0�\u0017�+���*�s�\\����\u0007.�X;�Ϭ�AT�PW����v��_��3=C[\u001e",
      "�B\u0006�\u0000\u0007�\u001b\"��`\\s^&\u0012�\u001e",
      "�\f",
      "&��׈�t\u000f\u000f�IY(\u0001�6�\u000e><��-�\u0001��\u001e",
      "޴u�}�:��h�'i�ψ.��\")�b��b\u0003C�%���D�7mg5��>\u0010ylz|x�d�k��h��\u000e��\u00067?24-\u0007��\u000fn�N�#��/\u0000I+���\r\n",
      "_\u000530�S�\u00040���\u0005<Yu;]����\u000f�]{\u001d",
      "\u001c",
      "\u0016C~��\u001f\f",
      "�Ʒ.�>�~V����O������T�(�\u0010��iϦ,F;�\t*t�Th�ZGu\tU�o�\u0013F�%x��\u000f�rЇ{`+��T�G�OqGI\u001a�=c�E>�[!\u001fW�i�{]v��iKs�RE�����<Z���7�\u0001�\u00156�\u0001�\u0000=��\u0017���C\u0013���J7��d:\r\n",
      "�TG�r�\u001d",
      "��Xa��<���GjS\u0004�<���]e���J���B��\u0013y��$�n�����\\\u000f��S=�4\u001d",
      "+%�W�G]���\u000b",
      "U|~��m�����$y�EM_q\u000f�\u001e",
      "t�T\u001a��\u0007Uv|�]M��r�{�2�{���\u0005Ū\u0005I�p�v�U��=�\u001a��H�ze�{�k�{9�\r\n",
      "]���T��1<\u0004exh̻�}�X����e\u0007U�Ʃ��J����K�J\u000e�6\u0015{KW������įͼ���y����3����\u001e",
      "s�9ےi�[[l\u0016�Ŭ⿌չMg�8�\u0011,�OYL\u0016A�\u001f��?�'\f",
      "���\u0016f\u0001K�����\u0017![���:G�+&�3�x�TRuBv�:�\u001b\u0006;�y��\u001d",
      "\u0018Z\u0018�\u0002\u0005�VM�s�p��.�^Gu���na�2s�}��D�r��#�\u001c",
      "s��*��\\�\u0019w�\f",
      "�t�Q2E�}���[O\r",
      "\u000f��\u0006�R ,\u0005�T�ʞ�S\u0019�\u0012œ���AT��pWwL���2(E�J��\u0017O\u000e\u001b�n1���a�\u0012z\u0003�'{�lX\u001e",
      "\u000eH\u0011�TW���Yc�N����/�U�w�E\u001f��hw�X���K\u001f�S\u001f�S\u001f�K�2��'\u001f��d��S\f",
      "���JI�ҼfCP\u0011#!��/���(\b\u0013`\u0017�A�0\u0002��\u0002p\u0003hoQ}[����\u000f�K`O\f",
      "h�jhQ���\u0012u�0\u0001O�!\u0018\u0005\u0013�L|\t<\b��e���F8\r",
      "ob!̧��\u0007\u0015V�OQ�^�^�g�\u001f�\u000b",
      "p\u0000NB:�\u0019�\u001c",
      "��C��8�2�]�C�G�\u0007��I8\u0007���>�Ԏj�Ⱥ\u0016�cp���\u0004%v���~��\u0016,����A�׵��(dB9�C;iw�y�rok1pB\r",
      "E�}x\u0001����\u0007|\u0002Ok1mX��]�Tu�\\蠲\r",
      "O�Un�R���{-AH�@\u0019�\u001a���O��(�\t�Z\u0003�U\u001c",
      "��x���\tv��)�&�\b�RXI�\t6�S��8\\���O�!srvn����D�_H�\u0016��>�(\f",
      "S�Ee\u001f��,�p!6`;n���\u0001|����Y�}�=�>�ڸ��V�\r",
      "�\u0011~L�+<gJK\\��j��_A.��\u0001�\u0002�iv\u0017�\r\n",
      "\\�O����\u0017k�\u001e",
      "\u001f�2���8\u001e",
      "�q֎\u0013x�\u001d",
      "�w�=�\u0010o0���\u001c",
      "�cCl?;�.��s}�\u0001�{ܻ�u�^�\tG��M^�&�\u0012�\u0013?�j���'��Z�C+S\u000fm�\u0010Dh���\u0018��fq��(��E�1\\6�{8\u0017&�\u0013B\u00010\u0013�\r\n",
      "[���}؋}x\u0018�P9o��1��`V�`�l.�`]l���_�\u0011��+�Vq\u001b�Q*�qor7�\u001b��g�9�J�\u0019��\u0003��T^�_���_\b�½B��^\u0018\u0011v\u000b",
      "{�n�u�M�v�>Ә�C��ж�ڼټ�V�2�쫔��x�G�W�נ\u001b��\u0005\u0007i5�`\u0004�]=�\u0014�5\b%Z'��[�\u0016R6��oP�>\u000f�`7�\u0011�h��\u001d",
      "�_S�l�.G��|=�����<\u0001\u000b",
      ")���\\ZVZR\\�'��G�-nA~�3wNNvV�Þ��f�Z�&��\u0018By@j\f",
      "�JQXዤ��\r\n",
      "]�\"��ܤ\b�_YT\u001ag�(��.B�Y�2y���)'=�'��Z��(\u0017\u0003����/�*nX\u0013$�i�\u0014\u0012�I�o5�g\f",
      ">�x��\u001a�\u0001g�/*\u0018\u0016\u0003J�p,\u001e",
      "\b�+�q\\&8l\u0015���!C�ޱ\u0002\r",
      "�m��B��\u0011P�%@ɓ�'\u001b�\r",
      "Dz��5�����\t��Tk�4FEy�Bq�\u001e",
      "�g�*CWX�\"\u001b�\r\n",
      "\u0017\t),����)��_�}�}��\u0019.��&�¼��h�Q��{\b\\]\f",
      "�Rd/I-\u001d",
      "\"u�v��\r\n",
      "�\u000eB���\"��M>\u0013��~Q�J�R,�\u001f&pamp,_�76_\u0005ڃcyr�!T��;��xh��\u0015+*V���ܞ���VR��\t�:�_�\r",
      "і�)\u0000PG@j�8\u0015��\u0018D�`���2�w/#��\r\n",
      "!M���iP\u0018�\f",
      "�U\u0004osD\u0019�\t#�O\u0006\u0017���Y��P}���q�rZ)�Kb�:=����\u001ffk\"�\u001a��~\u001d",
      "t��Щ\\Q02�\u000f�\u000fK/�:�b��\u000e\u001bkJ��\f",
      "ܤ Y�F�Yɦ\u0007x{У�!R��dy�\r\n",
      "���I�}!\u0015��*�]���=� ���T����$T����C��r��Fn�sE���枸�(�(�x�A�\u0010��\u0016\u0010�\u001d",
      "A�\t�шr� �FC����\u0002�\u001fjB��\u0010��?�\u0003QC�`��\u0016��Ô+j\u000f�\t*#�\u0002E��h\u0015(}'ڃ�\u0004en(D^��H)�m}�阫(��2�/J�B�.#�E(\u001e",
      "���\bJ\u001e",
      "e\"\u001e",
      "/������\"ܪ��\u0015*�.:�*��S[\"���X\u0003�䡰B:��)�g2��ٿ\u0018ᥩ���=\u0014�R\u0003�ew\b���Ax�m!\\��t\u0016µ\u0014s���W�<�p�\u0017#,�� WP���p�\u001d",
      "B��v\u0010��\u0016T��\u0010n��\u0003:�+�<��f!���\b�J�MA�P��\f",
      "�W�!�[o\u0007��B��T��\u0010n����\u0011^��!�v\u0016�\u001d",
      "_��T�\u0014��\u0014�:\u0003��w\b´\u001d",
      "����p(\u0015�,�7P�!\u001d",
      "�\u0007R\b�\u0005\r\n",
      "ܼ\u000f�ܲ��\u001d",
      "ߘ7�\u00049�)\t�PϪaRX\u000f�t�z��޵��4\u001d",
      "��J�S�\u0016�\u001e",
      "z�Nj\f",
      "���ƌV�_iK'{�����#\\�O�Kz=\u0000�΋\u001c",
      "}wjH~\u000b",
      "�,P��j��\u0000W��2��;�\u00135\u0013�Z߁3�\r\n",
      "`��\f",
      "�$\u0010]X���q\u0014S�������p��\u0006�o�A�\u0016�c����X\u0002=�\u0017�\u00054�}�2�--77��s�5A�-����7���v���Tu�Ŷ@��\u0001��M}PW�0k���8Ǣ\u001c",
      "i�'���/]\u0012�%\\S;�7?��\r\n",
      "͠�\u0010�\r\n",
      "���F'����&\f",
      "b\f",
      "������َ�T�j3��\u0010�&\u00132��J7\u001b�\u0005܋\u001c",
      "/f�l�L�e\u000b",
      "�7�\u001c",
      "��\u0004�j�M\u0002�1�\u0015�-*�d+�Λ�6N �e93#��\u0017\u000e�a[^z�\u0011��\u0007)���k�֩�<#�F�\u0013�rk�j[�j�j\u001d",
      "�u�Ȭ����z����m�\u0016z��'\r\n",
      "\u0014�bh�|紂#\u0005w1���e��5S�\\���Љi��\b%��I��{wr�U������/��=�6��S_�?m@5�d��\"��M\\\u0006��\u001f�ݻ\u001c",
      "\u00073Y�%��n\u0006��\u0016KeV~~������7=û��O��?n������ʅ\r",
      "[�\"����\u0014�̂�7sff\u0016L6��\r\n",
      "q\u000eݬ�iUhΦӖχ>_�����ު{��e��I\u001e",
      "\u0007�\u0011s�8�ͬ\u0014ٕ芡U5�w����\u000b",
      "��\u000e\\��\u0003�C�'�F��\u0014o\u000e��X�\u000e��9!��\u0017\u0012���\\b�r\u0007��\r",
      "��`���GS!�\u0019o�\u0012�p�q^��aʳ��ٯ�^#��%\u0013����`��8$�g\t9����C87��G�]��5e�qiQ:���K %O�0��\u001e",
      "␾H$��&�F\u000b",
      "\r",
      "���\r",
      "M�����P_w���e.1����~\u0000}G\u0000\bj�\u0017�⍹͒W�b��\"����\u0003��&\r\n",
      "\r\n",
      "endstream\r\n",
      "endobj\r\n",
      "14 0 obj\r\n",
      "3345\r\n",
      "endobj\r\n",
      "15 0 obj\r\n",
      "(dat)\r\n",
      "endobj\r\n",
      "16 0 obj\r\n",
      "(Mac OS X 10.12.4 Quartz PDFContext)\r\n",
      "endobj\r\n",
      "17 0 obj\r\n",
      "(Pages)\r\n",
      "endobj\r\n",
      "18 0 obj\r\n",
      "(D:20170414071811Z00'00')\r\n",
      "endobj\r\n",
      "1 0 obj\r\n",
      "<< /Title 15 0 R /Producer 16 0 R /Creator 17 0 R /CreationDate 18 0 R /ModDate\r\n",
      "18 0 R >>\r\n",
      "endobj\r\n",
      "xref\r\n",
      "0 19\r\n",
      "0000000000 65535 f \r\n",
      "0000007501 00000 n \r\n",
      "0000000268 00000 n \r\n",
      "0000003239 00000 n \r\n",
      "0000000022 00000 n \r\n",
      "0000000249 00000 n \r\n",
      "0000000372 00000 n \r\n",
      "0000003204 00000 n \r\n",
      "0000003372 00000 n \r\n",
      "0000000469 00000 n \r\n",
      "0000003183 00000 n \r\n",
      "0000003322 00000 n \r\n",
      "0000003654 00000 n \r\n",
      "0000003904 00000 n \r\n",
      "0000007339 00000 n \r\n",
      "0000007360 00000 n \r\n",
      "0000007382 00000 n \r\n",
      "0000007435 00000 n \r\n",
      "0000007459 00000 n \r\n",
      "trailer\r\n",
      "<< /Size 19 /Root 11 0 R /Info 1 0 R /ID [ <e4c4892da9e4210e1337861985e5f085>\r\n",
      "<e4c4892da9e4210e1337861985e5f085> ] >>\r\n",
      "startxref\r\n",
      "7606\r\n",
      "%%EOF\r\n"
     ]
    }
   ],
   "source": [
    "!cat files/dat.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"750\"\n",
       "            height=\"300\"\n",
       "            src=\"./files/dat.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x11656b240>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out what the PDF actually looks like (in rendered form)\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"./files/dat.pdf\", width=750, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Binary Files\n",
    "\n",
    "- Binary files contain data stored in binary format\n",
    "- They can only be loaded by a program that understands their structure\n",
    "- Think of them like a string of uninterpretable numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define an array, with numpy\n",
    "array = np.array([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Save the array to a numpy binary file (.npy)\n",
    "np.save('files/data', array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000000 93 4e 55 4d 50 59 01 00 46 00 7b 27 64 65 73 63\r\n",
      "0000010 72 27 3a 20 27 3c 69 38 27 2c 20 27 66 6f 72 74\r\n",
      "0000020 72 61 6e 5f 6f 72 64 65 72 27 3a 20 46 61 6c 73\r\n",
      "0000030 65 2c 20 27 73 68 61 70 65 27 3a 20 28 35 2c 29\r\n",
      "0000040 2c 20 7d 20 20 20 20 20 20 20 20 20 20 20 20 0a\r\n",
      "0000050 01 00 00 00 00 00 00 00 02 00 00 00 00 00 00 00\r\n",
      "0000060 03 00 00 00 00 00 00 00 04 00 00 00 00 00 00 00\r\n",
      "0000070 05 00 00 00 00 00 00 00                        \r\n",
      "0000078\r\n"
     ]
    }
   ],
   "source": [
    "# Display the contents of the file, in hexadecimal\n",
    "!hexdump files/data.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# Load and display the npy file\n",
    "new_array = np.load('files/data.npy')\n",
    "print(new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Complex objects\n",
    "\n",
    "class Data(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.numbers = []\n",
    "        self.letters = []\n",
    "         \n",
    "    def set_numbers(self, numbers_in):\n",
    "        \n",
    "        self.numbers = numbers_in\n",
    "        \n",
    "    def set_letters(self, letters_in):\n",
    "        \n",
    "        self.letters = letters_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize an object\n",
    "data = Data()\n",
    "\n",
    "# Add data to our instantiation of the object\n",
    "data.set_numbers([1, 2, 3, 4, 5])\n",
    "data.set_letters(['a', 'b', 'c', 'd', 'e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Data object at 0x116536908>\n",
      "\n",
      "\n",
      "[1, 2, 3, 4, 5]\n",
      "['a', 'b', 'c', 'd', 'e']\n"
     ]
    }
   ],
   "source": [
    "# Check out the object\n",
    "print(data)\n",
    "print('\\n')\n",
    "print(data.numbers)\n",
    "print(data.letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# You can save complex objects, to binary, using pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Save out a pickle file of our data object\n",
    "with open('files/data.p', 'wb') as pickle_file:\n",
    "    pickle.dump(data, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000000 80 03 63 5f 5f 6d 61 69 6e 5f 5f 0a 44 61 74 61\r\n",
      "0000010 0a 71 00 29 81 71 01 7d 71 02 28 58 07 00 00 00\r\n",
      "0000020 6e 75 6d 62 65 72 73 71 03 5d 71 04 28 4b 01 4b\r\n",
      "0000030 02 4b 03 4b 04 4b 05 65 58 07 00 00 00 6c 65 74\r\n",
      "0000040 74 65 72 73 71 05 5d 71 06 28 58 01 00 00 00 61\r\n",
      "0000050 71 07 58 01 00 00 00 62 71 08 58 01 00 00 00 63\r\n",
      "0000060 71 09 58 01 00 00 00 64 71 0a 58 01 00 00 00 65\r\n",
      "0000070 71 0b 65 75 62 2e                              \r\n",
      "0000076\r\n"
     ]
    }
   ],
   "source": [
    "!hexdump files/data.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Databases\n",
    "\n",
    "- A database is an organized collection of data. \n",
    "- More formally, 'database' refers to a set of related data, and the way it is organized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/sql.png\" alt=\"sql\" height=\"400\" width=\"400\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Web Portals with Available Data\n",
    "\n",
    "- https://www.data.gov/\n",
    "- https://data.sandiego.gov/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/data_gov.png\" alt=\"gov_dat\" height=\"500\" width=\"750\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/sd_data.png\" alt=\"sd_dat\" height=\"500\" width=\"750\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Application Program Interface (APIs)\n",
    "\n",
    "- APIs are basically a way for software to talk to software \n",
    "    - They are an interface into an application / website / database designed for computers / software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notes on APIs:\n",
    "- Follow API guidelines! \n",
    "    - These guidelines typically specify the number / rate / size of requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/pubmed.png\" alt=\"sql\" height=\"400\" width=\"400\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Pubmed API\n",
    "\n",
    "You can access the Pubmed search API with the following API. Add a term at the end to search for. \n",
    "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?'&term="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/twitter.png\" alt=\"sql\" height=\"250\" width=\"250\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kristian Lum\n",
      "And also this: https://t.co/riNKDoE0HD\n",
      "\n",
      "It's certainly consistent with my experience. I remember tons of bees and o… https://t.co/E8PWO6y9uP \n",
      "\n",
      "Sanjay Srivastava\n",
      "RT @uolibraries: With great sadness we learned today of the passing of Ursula K. Le Guin, master of speculative fiction and longtime friend… \n",
      "\n",
      "Greg Jenner\n",
      "I would like Spurs to buy this footballer , please \n",
      "\n",
      "DAVID NERES - Incredible Goals, Skills &amp; Assists - 2017 (HD)… https://t.co/pTeWc8gY0c \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accessing Twitter API from Python\n",
    "#  Note: to run this, you will have to fill in stw.py with your OAuth credentials.\n",
    "#    You can do that here: https://apps.twitter.com/\n",
    "\n",
    "# Import tweepy to access API\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "# Import my API credentials\n",
    "from stw import *\n",
    "\n",
    "# Twitter API requires Authentification with OAuth\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "# Create an API object to access Twitter\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "for status in tweepy.Cursor(api.home_timeline).items(3):\n",
    "    # Process a single status\n",
    "    print(status.user.name)\n",
    "    print(status.text, '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Check out some information of the API object\n",
    "api?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Authorized Access - OAuth\n",
    "\n",
    "Open Authorization is a protocol to authorize access (of a user / application) to an API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "OAuth provides a secure way to 'log-in' without using account names and passwords. \n",
    "\n",
    "It is effectively a set of keys, and passwords you can use to access APIs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"img/github.png\" alt=\"sql\" height=\"250\" width=\"250\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Github API\n",
    "\n",
    "You can access the github api with the following API. Just added specifiers for what you are looking for. \n",
    "\n",
    "https://api.github.com/\n",
    "\n",
    "For example, the following URL will search for the user 'TomDonoghue'\n",
    "\n",
    "https://api.github.com/users/tomdonoghue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Requesting Web Pages from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# The requests module allows you to send URL requests from python\n",
    "import requests  \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Request data from the Github API on a particular user\n",
    "page = requests.get('https://api.github.com/users/tomdonoghue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"login\":\"TomDonoghue\",\"id\":7727566,\"avatar_url\":\"https://avatars0.githubusercontent.com/u/7727566?v=4\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/TomDonoghue\",\"html_url\":\"https://github.com/TomDonoghue\",\"followers_url\":\"https://api.github.com/users/TomDonoghue/followers\",\"following_url\":\"https://api.github.com/users/TomDonoghue/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/TomDonoghue/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/TomDonoghue/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/TomDonoghue/subscriptions\",\"organizations_url\":\"https://api.github.com/users/TomDonoghue/orgs\",\"repos_url\":\"https://api.github.com/users/TomDonoghue/repos\",\"events_url\":\"https://api.github.com/users/TomDonoghue/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/TomDonoghue/received_events\",\"type\":\"User\",\"site_admin\":false,\"name\":\"Tom\",\"company\":\"UC San Diego\",\"blog\":\"tomdonoghue.github.io\",\"location\":\"San Diego\",\"email\":null,\"hireable\":null,\"bio\":\"Cognitive Science Grad Student @ UCSD. \\\\r\\\\nOn Twitter @TomDonoghue\",\"public_repos\":13,\"public_gists\":0,\"followers\":12,\"following\":33,\"created_at\":\"2014-05-28T20:20:48Z\",\"updated_at\":\"2018-01-09T04:15:59Z\"}'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The content we get back is a messily organized json file\n",
    "page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avatar_url             https://avatars0.githubusercontent.com/u/77275...\n",
       "bio                    Cognitive Science Grad Student @ UCSD. \\r\\nOn ...\n",
       "blog                                               tomdonoghue.github.io\n",
       "company                                                     UC San Diego\n",
       "created_at                                          2014-05-28T20:20:48Z\n",
       "email                                                               None\n",
       "events_url             https://api.github.com/users/TomDonoghue/event...\n",
       "followers                                                             12\n",
       "followers_url          https://api.github.com/users/TomDonoghue/follo...\n",
       "following                                                             33\n",
       "following_url          https://api.github.com/users/TomDonoghue/follo...\n",
       "gists_url              https://api.github.com/users/TomDonoghue/gists...\n",
       "gravatar_id                                                             \n",
       "hireable                                                            None\n",
       "html_url                                  https://github.com/TomDonoghue\n",
       "id                                                               7727566\n",
       "location                                                       San Diego\n",
       "login                                                        TomDonoghue\n",
       "name                                                                 Tom\n",
       "organizations_url          https://api.github.com/users/TomDonoghue/orgs\n",
       "public_gists                                                           0\n",
       "public_repos                                                          13\n",
       "received_events_url    https://api.github.com/users/TomDonoghue/recei...\n",
       "repos_url                 https://api.github.com/users/TomDonoghue/repos\n",
       "site_admin                                                         False\n",
       "starred_url            https://api.github.com/users/TomDonoghue/starr...\n",
       "subscriptions_url      https://api.github.com/users/TomDonoghue/subsc...\n",
       "type                                                                User\n",
       "updated_at                                          2018-01-09T04:15:59Z\n",
       "url                             https://api.github.com/users/TomDonoghue\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can read in the json data with pandas\n",
    "pd.read_json(page.content, typ='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" ?><!DOCTYPE PubmedArticleSet PUBLIC \"-//NLM//DTD PubMedArticle, 1st January 2018//EN\" \"https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_180101.dtd\">\n",
      "<html><body><pubmedarticleset>\n",
      "<pubmedarticle>\n",
      "<medlinecitation owner=\"NLM\" status=\"In-Process\">\n",
      "<pmid version=\"1\">28410530</pmid>\n",
      "<daterevised>\n",
      "<year>2017</year>\n",
      "<month>05</month>\n",
      "<day>20</day>\n",
      "</daterevised>\n",
      "<article pubmodel=\"Print-Electronic\">\n",
      "<journal>\n",
      "<issn issntype=\"Electronic\">1878-1705</issn>\n",
      "<journalissue citedmedium=\"Internet\">\n",
      "<volume>47</volume>\n",
      "<pubdate>\n",
      "<year>2017</year>\n",
      "<month>Jun</month>\n",
      "</pubdate>\n",
      "</journalissue>\n",
      "<title>International immunopharmacology</title>\n",
      "<isoabbreviation>Int. Immunopharmacol.</isoabbreviation>\n",
      "</journal>\n",
      "<articletitle>Metformin attenuated endotoxin-induced acute myocarditis via activating AMPK.</articletitle>\n",
      "<pagination>\n",
      "<medlinepgn>166-172</medlinepgn>\n",
      "</pagination>\n",
      "<elocationid eidtype=\"pii\" validyn=\"Y\">S1567-5769(17)30136-4</elocationid>\n",
      "<elocationid eidtype=\"doi\" validyn=\"Y\">10.1016/j.intimp.2017.04.002</elocationid>\n",
      "<abstract>\n",
      "<abstracttext>Metformin is a widely used anti-diabetic drug and increasing evidence suggests that metformin have profound cardioprotective effects under both diabetic and non-diabetic situations. The protective benefits of metformin have been proved in diabetic patients with cardiovascular complications and in experimental animals with myocardial infarction and cardiac hypertrophy. In the present study, we found that treatment with metformin inhibited the cardiac expression of pro-inflammatory cytokines including tumor necrosis factor alpha (TNF-α), interleukin 1 beta (IL-1β) and interleukin 6 (IL-6) in endotoxin-challenged mice. Treatment with metformin also alleviated the histological abnormalities in the heart, suppressed the upregulation of myeloperoxidase (MPO), decreased the elevation of creatinine kinase-myocardial band (CK-MB) and brain natriuretic peptide (BNP). Treatment with metformin promoted the phosphorylation of the catalytic α subunit of adenosine 5'-monophosphate-activated protein kinase (AMPKα), co-administration of AMPK inhibitor suppressed the stimulatory effects of metformin on AMPKα phosphorylation. Meanwhile, the suppressive effects of metformin on MPO, TNF-α, CK-MB and BNP were reversed by the AMPK inhibitor. On the contrary, administration of AMPK activator mimicked the effects of metformin on AMPKα phosphorylation, MPO upregulation, CK-MB release and BNP elevation. These evidence suggested that metformin might provide beneficial effects in endotoxin-induced acute myocarditis via activating AMPK-dependent anti-inflammatory mechanism.</abstracttext>\n",
      "<copyrightinformation>Copyright © 2017 Elsevier B.V. All rights reserved.</copyrightinformation>\n",
      "</abstract>\n",
      "<authorlist completeyn=\"Y\">\n",
      "<author validyn=\"Y\">\n",
      "<lastname>Liu</lastname>\n",
      "<forename>Gang</forename>\n",
      "<initials>G</initials>\n",
      "<affiliationinfo>\n",
      "<affiliation>Department of Emergency, University-Town Hospital of Chongqing Medical University, Chongqing, China.</affiliation>\n",
      "</affiliationinfo>\n",
      "</author>\n",
      "<author validyn=\"Y\">\n",
      "<lastname>Wu</lastname>\n",
      "<forename>Kejia</forename>\n",
      "<initials>K</initials>\n",
      "<affiliationinfo>\n",
      "<affiliation>Department of Pathophysiology, Chongqing Medical University, Chongqing, China.</affiliation>\n",
      "</affiliationinfo>\n",
      "</author>\n",
      "<author validyn=\"Y\">\n",
      "<lastname>Zhang</lastname>\n",
      "<forename>Li</forename>\n",
      "<initials>L</initials>\n",
      "<affiliationinfo>\n",
      "<affiliation>Department of Pathophysiology, Chongqing Medical University, Chongqing, China.</affiliation>\n",
      "</affiliationinfo>\n",
      "</author>\n",
      "<author validyn=\"Y\">\n",
      "<lastname>Dai</lastname>\n",
      "<forename>Jie</forename>\n",
      "<initials>J</initials>\n",
      "<affiliationinfo>\n",
      "<affiliation>Hospital of Chongqing University of Arts and Sciences, Chongqing, China.</affiliation>\n",
      "</affiliationinfo>\n",
      "</author>\n",
      "<author validyn=\"Y\">\n",
      "<lastname>Huang</lastname>\n",
      "<forename>Wei</forename>\n",
      "<initials>W</initials>\n",
      "<affiliationinfo>\n",
      "<affiliation>Department of Cardiology, The First Affiliated Hospital of Chongqing Medical University, Chongqing, China.</affiliation>\n",
      "</affiliationinfo>\n",
      "</author>\n",
      "<author validyn=\"Y\">\n",
      "<lastname>Lin</lastname>\n",
      "<forename>Ling</forename>\n",
      "<initials>L</initials>\n",
      "<affiliationinfo>\n",
      "<affiliation>Department of Pathophysiology, Chongqing Medical University, Chongqing, China.</affiliation>\n",
      "</affiliationinfo>\n",
      "</author>\n",
      "<author validyn=\"Y\">\n",
      "<lastname>Ge</lastname>\n",
      "<forename>Pu</forename>\n",
      "<initials>P</initials>\n",
      "<affiliationinfo>\n",
      "<affiliation>Department of Pathophysiology, Chongqing Medical University, Chongqing, China.</affiliation>\n",
      "</affiliationinfo>\n",
      "</author>\n",
      "<author validyn=\"Y\">\n",
      "<lastname>Luo</lastname>\n",
      "<forename>Fuling</forename>\n",
      "<initials>F</initials>\n",
      "<affiliationinfo>\n",
      "<affiliation>Department of Pharmacy, the First Affiliated Hospital of Chongqing Medical University, Chongqing, China.</affiliation>\n",
      "</affiliationinfo>\n",
      "</author>\n",
      "<author validyn=\"Y\">\n",
      "<lastname>Lei</lastname>\n",
      "<forename>Han</forename>\n",
      "<initials>H</initials>\n",
      "<affiliationinfo>\n",
      "<affiliation>Department of Cardiology, The First Affiliated Hospital of Chongqing Medical University, Chongqing, China. Electronic address: leihan@cqmu.edu.cn.</affiliation>\n",
      "</affiliationinfo>\n",
      "</author>\n",
      "</authorlist>\n",
      "<language>eng</language>\n",
      "<publicationtypelist>\n",
      "<publicationtype ui=\"D016428\">Journal Article</publicationtype>\n",
      "</publicationtypelist>\n",
      "<articledate datetype=\"Electronic\">\n",
      "<year>2017</year>\n",
      "<month>04</month>\n",
      "<day>12</day>\n",
      "</articledate>\n",
      "</article>\n",
      "<medlinejournalinfo>\n",
      "<country>Netherlands</country>\n",
      "<medlineta>Int Immunopharmacol</medlineta>\n",
      "<nlmuniqueid>100965259</nlmuniqueid>\n",
      "<issnlinking>1567-5769</issnlinking>\n",
      "</medlinejournalinfo>\n",
      "<keywordlist owner=\"NOTNLM\">\n",
      "<keyword majortopicyn=\"N\">AMP-activated protein kinase</keyword>\n",
      "<keyword majortopicyn=\"N\">Endotoxin</keyword>\n",
      "<keyword majortopicyn=\"N\">Inflammation</keyword>\n",
      "<keyword majortopicyn=\"N\">Metformin</keyword>\n",
      "<keyword majortopicyn=\"N\">Myocarditis</keyword>\n",
      "</keywordlist>\n",
      "</medlinecitation>\n",
      "<pubmeddata>\n",
      "<history>\n",
      "<pubmedpubdate pubstatus=\"received\">\n",
      "<year>2016</year>\n",
      "<month>11</month>\n",
      "<day>25</day>\n",
      "</pubmedpubdate>\n",
      "<pubmedpubdate pubstatus=\"revised\">\n",
      "<year>2017</year>\n",
      "<month>03</month>\n",
      "<day>22</day>\n",
      "</pubmedpubdate>\n",
      "<pubmedpubdate pubstatus=\"accepted\">\n",
      "<year>2017</year>\n",
      "<month>04</month>\n",
      "<day>03</day>\n",
      "</pubmedpubdate>\n",
      "<pubmedpubdate pubstatus=\"pubmed\">\n",
      "<year>2017</year>\n",
      "<month>4</month>\n",
      "<day>15</day>\n",
      "<hour>6</hour>\n",
      "<minute>0</minute>\n",
      "</pubmedpubdate>\n",
      "<pubmedpubdate pubstatus=\"medline\">\n",
      "<year>2017</year>\n",
      "<month>4</month>\n",
      "<day>15</day>\n",
      "<hour>6</hour>\n",
      "<minute>0</minute>\n",
      "</pubmedpubdate>\n",
      "<pubmedpubdate pubstatus=\"entrez\">\n",
      "<year>2017</year>\n",
      "<month>4</month>\n",
      "<day>15</day>\n",
      "<hour>6</hour>\n",
      "<minute>0</minute>\n",
      "</pubmedpubdate>\n",
      "</history>\n",
      "<publicationstatus>ppublish</publicationstatus>\n",
      "<articleidlist>\n",
      "<articleid idtype=\"pubmed\">28410530</articleid>\n",
      "<articleid idtype=\"pii\">S1567-5769(17)30136-4</articleid>\n",
      "<articleid idtype=\"doi\">10.1016/j.intimp.2017.04.002</articleid>\n",
      "</articleidlist>\n",
      "</pubmeddata>\n",
      "</pubmedarticle>\n",
      "</pubmedarticleset></body></html>\n"
     ]
    }
   ],
   "source": [
    "# Request the page from Python, using requests\n",
    "page = requests.get(\"http://eutils.ncbi.nlm.nih.gov/entrez/\" \\\n",
    "                    \"eutils/efetch.fcgi?&retmode=xml&db=pubmed&id=28410530\")\n",
    "\n",
    "# 'Clean Up', organize the data, with Beautiful Soup\n",
    "pretty_pubmed_data = BeautifulSoup(page.content, 'lxml')\n",
    "\n",
    "# Print out our data, in a nicer format\n",
    "print(pretty_pubmed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Web Scraping vs. APIs\n",
    "\n",
    "Web scraping and APIs are different approaches:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- APIs are an interface to interact with an application, designed for programmatic use\n",
    "    - They allow systematic, controlled access to (for example) and applications database\n",
    "    - They typically return structured (friendly) data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Web scraping (typically) involves navigating through the internet, programmatically following an architecture built for humans\n",
    "    - This can be hard to systematize, being dependent on the idiosyncracies of a web page, at the time you request it\n",
    "    - This typically returns relatively unstructured data\n",
    "    - This entails much more wrangling of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unstructured Data\n",
    "<br>\n",
    "Large amounts of data are stored in unstrucured formats, such as free form text files. This kind of data takes a lot of wrangling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLINICAL HISTORY:  This is a 75-year-old female with history of bilateral MCA stroke who presents with staring spells concerned for complex partial seizures.\r\n",
      "\r\n",
      "MEDICATIONS:  Levetiracetam, gabapentin, metoprolol, atorvastatin.\r\n",
      "\r\n",
      "INTRODUCTION:  Digital video EEG was performed at the bedside using standard 10/20 system of electrode placement with 1 channel EKG.  Hyperventilation and photic stimulation were not performed.\r\n",
      "\r\n",
      "DESCRIPTION OF THE RECORD:  This is a technically limited EEG with muscle artifact throughout the recording.  There was no cerebral waveform activity were detectable.  Heart rate was 60 beats per minute and regular.\r\n",
      "\r\n",
      "IMPRESSION:  This is a technically limited EEG due to diffuse muscle artifact throughout the recording.\r\n",
      "\r\n",
      "CLINICAL IMPRESSION:  The EEG was not readable.  A repeat EEG is recommended.\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Unstructured Text / Data: Example from a public database on clinical brain (EEG) recordings\n",
    "!cat files/00000201_eg.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# What we really want, is this data organized into data objects\n",
    "#  For example, we can use a pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "labels = ['Name', 'Medication', 'IsReadable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dat = ['S1', ['Levetiracetam', 'gabapentin', 'metoprolo', 'atorvastatin'], False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ser = pd.Series(dat, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                                                         S1\n",
      "Medication    [Levetiracetam, gabapentin, metoprolo, atorvas...\n",
      "IsReadable                                                False\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ser) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name                                         Medication  IsReadable\n",
      "0   S1  [Levetiracetam, gabapentin, metoprolo, atorvas...       False\n",
      "1   S2                                                 []        True\n"
     ]
    }
   ],
   "source": [
    "# Really, we want this for all subjects, combined into a friendly dataframe\n",
    "\n",
    "# Make second subject\n",
    "dat_2 = ['S2', [], True]\n",
    "ser_2 = pd.Series(dat_2, labels)\n",
    " \n",
    "# Create the dataframe\n",
    "df = pd.DataFrame([ser, ser_2])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name Medication  IsReadable\n",
      "1   S2         []        True\n"
     ]
    }
   ],
   "source": [
    "# Then we could index to only keep subjects with readable data\n",
    "good_dat = df.loc[df['IsReadable'] == True]\n",
    "print(good_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note, however, the massive wrangling problem we have here. \n",
    "\n",
    "How can we systematically and consistently get 10,000 unstructured text files into a friendly dataframe to explore?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(Seriously - if you figure it out, let me know)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Wrangling: How did we get here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Science is Ad-Hoc\n",
    "\n",
    "- It is part of the job description to put things together that were not designed to go together.\n",
    "- We do not have universal solutions, but haphazard, idiosyncratic systems, for data collection, storage and analysis.\n",
    "- Data is everywhere. But relatively little of it was collected *as data*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data Collection, Curation, and Storage are Difficult\n",
    "\n",
    "- It can be difficult to choose broadly useful standards\n",
    "- Take time to think about your data, and how you will load, store, organize and save it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data is Inherently Noisy\n",
    "\n",
    "- We live in a messy, noisy, world, with messy, noisy, people, using messy, noisy instruments.\n",
    "- There is no perfect data. \n",
    "    - There is better / or worse data, given the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Different Objectives\n",
    "\n",
    "- Humans and computers are different.\n",
    "- We interact with '*data*' in different ways.\n",
    "- This underlies many aspects of data wrangling\n",
    "    - The 'friendliness' of data types / files\n",
    "    - The difference between web scraping and APIs\n",
    "    - A disconnect between data in the real world, and data we want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## So... What to do?\n",
    "\n",
    "- Consider ecological validity (to what extent does your data map to the real world)\n",
    "    - Data wrangling and cleaning issues are likely to scale with ecological validity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Consider the fidelity of the data you are using\n",
    "    - Try to get a feeling of the signal to noise ratio of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Develop a theory of mind for {computers, python}\n",
    "    - Try to understand what your computer 'wants'.\n",
    "    - Was the data you are interested organized and stored for a computer, or a human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What is the *context* of the data\n",
    "    - How was it generated, and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Specific Recommendations\n",
    "\n",
    "- Look for APIs. Ask if they are available.\n",
    "    - Acknowledge that web scraping and/or wrangling unstructured data are complex / long tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Prioritize using well structured, common, open file types\n",
    "    - Take advantage of existing tools to deal with these files (numpy, pandas, etc.)\n",
    "- Look into, and then follow, common conventions\n",
    "    - Minimize custom objects, workflows and data files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Think about data flow from the beginning. Organize your data pipeline, consider the 'wrangling' aspects throughout\n",
    "    - Set yourself up with well organized, labelled approach to your data\n",
    "    - Think about when and how you might want/need to save out intermediate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The End!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
